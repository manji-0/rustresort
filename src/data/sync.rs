//! Database synchronization helpers.

use chrono::Utc;
use sha2::{Digest, Sha256};
use std::io::Write;
use std::path::{Path, PathBuf};
use std::time::Instant;
use tokio::process::Command;
use ulid::Ulid;

use crate::config::D1SyncConfig;
use crate::error::AppError;

const D1_SYNC_HISTORY_TABLE: &str = "_rustresort_sync_history";
const D1_SYNC_HISTORY_TABLE_PRESENT_TOKEN: &str = "RUSTRESORT_SYNC_HISTORY_TABLE_PRESENT";
const D1_SYNC_KEY_PRESENT_TOKEN: &str = "RUSTRESORT_SYNC_KEY_PRESENT";

/// Sync local SQLite/Turso file DB to Cloudflare D1 via wrangler CLI.
///
/// Strategy:
/// 1. First sync (no snapshot): reset known local objects, then full SQL dump upload.
/// 2. Subsequent syncs: upload SQL diff generated by `sqldiff` against snapshot.
/// 3. On successful upload: promote the exact source snapshot used for payload generation.
pub async fn sync_to_d1(db_path: &Path, config: &D1SyncConfig) -> Result<(), AppError> {
    let started = Instant::now();
    let observe = |status: &str| crate::metrics::observe_db_sync("d1", status, started.elapsed());

    let database = match config
        .database
        .as_deref()
        .map(str::trim)
        .filter(|value| !value.is_empty())
    {
        Some(value) => value,
        None => {
            let error = AppError::Config(
                "database.sync.d1.database is required and must not be empty when database.sync.mode=d1"
                    .to_string(),
            );
            observe("error");
            return Err(error);
        }
    };

    let snapshot_path = resolve_snapshot_path(db_path, config);
    if let Err(error) = ensure_parent_dir(&snapshot_path).await {
        observe("error");
        return Err(error);
    }
    let canonical_snapshot_path =
        match validate_and_canonicalize_snapshot_path(db_path, &snapshot_path) {
            Ok(path) => path,
            Err(error) => {
                observe("error");
                return Err(error);
            }
        };

    let sync_source = match create_sync_source_snapshot(db_path, &canonical_snapshot_path).await {
        Ok(snapshot) => snapshot,
        Err(error) => {
            observe("error");
            return Err(error);
        }
    };

    let (payload_sql, sync_mode) = match path_exists(&canonical_snapshot_path).await {
        Ok(true) => match build_diff_sql(&canonical_snapshot_path, &sync_source.path).await {
            Ok(sql) => (sql, "diff"),
            Err(error) => {
                observe("error");
                return Err(error);
            }
        },
        Ok(false) => {
            tracing::info!(
                snapshot = %canonical_snapshot_path.display(),
                "D1 snapshot not found; performing initial full sync"
            );
            match build_full_dump_sql(&sync_source.path).await {
                Ok(sql) => (sql, "full"),
                Err(error) => {
                    observe("error");
                    return Err(error);
                }
            }
        }
        Err(error) => {
            observe("error");
            return Err(error);
        }
    };

    if payload_sql.is_empty() || String::from_utf8_lossy(&payload_sql).trim().is_empty() {
        tracing::info!("No D1 diff changes detected; skipping sync");
        observe("skipped");
        return Ok(());
    }

    let canonical_payload = canonicalize_sql_for_hash(&payload_sql);
    let sync_key = sha256_hex(canonical_payload.as_bytes());

    match d1_sync_key_exists(database, config, &sync_key).await {
        Ok(true) => {
            tracing::info!(
                sync_key = %sync_key,
                "D1 sync key already exists; treating as already-synced success"
            );
            if let Err(error) = promote_snapshot(&sync_source.path, &canonical_snapshot_path).await
            {
                observe("error");
                return Err(error);
            }
            if let Err(error) = prune_sync_history(database, config).await {
                tracing::warn!(%error, "Failed to prune D1 sync history");
            }
            observe("duplicate");
            return Ok(());
        }
        Ok(false) => {}
        Err(error) => {
            observe("error");
            return Err(error);
        }
    }

    let sync_name = Ulid::new().to_string();
    let sync_at = Utc::now().to_rfc3339();
    let sql_bytes = wrap_sync_sql(&payload_sql, &sync_key, &sync_name, &sync_at, sync_mode);

    let mut sql_file = match tempfile::Builder::new()
        .prefix("rustresort-d1-sync-")
        .suffix(&format!("-{}.sql", Ulid::new()))
        .tempfile()
    {
        Ok(file) => file,
        Err(error) => {
            observe("error");
            return Err(AppError::Storage(format!(
                "failed to create D1 SQL temp file: {error}"
            )));
        }
    };
    if let Err(error) = sql_file.write_all(&sql_bytes) {
        observe("error");
        return Err(AppError::Storage(format!(
            "failed to write D1 SQL temp file: {error}"
        )));
    }
    if let Err(error) = sql_file.flush() {
        observe("error");
        return Err(AppError::Storage(format!(
            "failed to flush D1 SQL temp file: {error}"
        )));
    }

    // NamedTempFile removes the SQL file on drop, including all error paths.
    if let Err(error) = execute_wrangler_d1(database, config, sql_file.path()).await {
        observe("error");
        return Err(error);
    }

    if let Err(error) = promote_snapshot(&sync_source.path, &canonical_snapshot_path).await {
        observe("error");
        return Err(error);
    }
    tracing::info!(
        snapshot = %canonical_snapshot_path.display(),
        "D1 snapshot refreshed from synchronized source snapshot"
    );

    if let Err(error) = prune_sync_history(database, config).await {
        tracing::warn!(%error, "Failed to prune D1 sync history");
    }

    observe("success");
    Ok(())
}

fn resolve_snapshot_path(db_path: &Path, config: &D1SyncConfig) -> PathBuf {
    if let Some(path) = &config.snapshot_path {
        return path.clone();
    }

    let mut snapshot_path = db_path.to_path_buf();
    let file_name = db_path
        .file_name()
        .and_then(|name| name.to_str())
        .map(|name| format!("{name}.d1-sync-snapshot.db"))
        .unwrap_or_else(|| "rustresort.d1-sync-snapshot.db".to_string());
    snapshot_path.set_file_name(file_name);
    snapshot_path
}

fn escape_sql_literal(value: &str) -> String {
    value.replace('\'', "''")
}

fn sha256_hex(bytes: &[u8]) -> String {
    let digest = Sha256::digest(bytes);
    digest
        .iter()
        .map(|byte| format!("{:02x}", byte))
        .collect::<String>()
}

fn canonicalize_sql_for_hash(payload_sql: &[u8]) -> String {
    String::from_utf8_lossy(payload_sql)
        .lines()
        .map(str::trim)
        .filter(|line| !line.is_empty())
        .collect::<Vec<_>>()
        .join("\n")
}

fn wrap_sync_sql(
    payload_sql: &[u8],
    sync_key: &str,
    sync_name: &str,
    sync_at: &str,
    sync_mode: &str,
) -> Vec<u8> {
    let table = D1_SYNC_HISTORY_TABLE;
    let sync_key = escape_sql_literal(sync_key);
    let sync_name = escape_sql_literal(sync_name);
    let sync_at = escape_sql_literal(sync_at);
    let sync_mode = escape_sql_literal(sync_mode);

    let create_table_sql = format!(
        r#"
CREATE TABLE IF NOT EXISTS "{table}" (
    sync_key TEXT PRIMARY KEY,
    sync_name TEXT NOT NULL,
    sync_at TEXT NOT NULL,
    sync_mode TEXT NOT NULL
);
    "#
    );

    let insert_sql = format!(
        r#"
INSERT INTO "{table}" (sync_key, sync_name, sync_at, sync_mode)
VALUES ('{sync_key}', '{sync_name}', '{sync_at}', '{sync_mode}');
"#
    );

    let mut wrapped =
        Vec::with_capacity(create_table_sql.len() + payload_sql.len() + insert_sql.len() + 2);
    wrapped.extend_from_slice(create_table_sql.as_bytes());
    if !create_table_sql.ends_with('\n') {
        wrapped.push(b'\n');
    }
    wrapped.extend_from_slice(payload_sql);
    if !payload_sql.is_empty() && !payload_sql.ends_with(b"\n") {
        wrapped.push(b'\n');
    }
    wrapped.extend_from_slice(insert_sql.as_bytes());
    wrapped
}

/// Validate D1 sync runtime requirements at startup.
pub fn validate_d1_sync_environment(config: &D1SyncConfig) -> Result<(), AppError> {
    config
        .database
        .as_deref()
        .map(str::trim)
        .filter(|value| !value.is_empty())
        .ok_or_else(|| {
            AppError::Config(
                "database.sync.d1.database is required and must not be empty when database.sync.mode=d1"
                    .to_string(),
            )
        })?;

    for tool in ["sqlite3", "sqldiff", "wrangler"] {
        ensure_cli_available(tool)?;
    }

    Ok(())
}

fn ensure_cli_available(tool: &str) -> Result<(), AppError> {
    let output = std::process::Command::new(tool)
        .arg("--version")
        .output()
        .map_err(|error| {
            AppError::Config(format!(
                "database.sync.mode=d1 requires `{tool}` in PATH: {error}"
            ))
        })?;

    if !output.status.success() {
        return Err(AppError::Config(format!(
            "database.sync.mode=d1 requires a working `{tool}` executable (`{tool} --version` failed)"
        )));
    }

    Ok(())
}

struct SyncSourceSnapshot {
    _temp_dir: tempfile::TempDir,
    path: PathBuf,
}

async fn create_sync_source_snapshot(
    db_path: &Path,
    snapshot_path: &Path,
) -> Result<SyncSourceSnapshot, AppError> {
    let parent = snapshot_path.parent().unwrap_or_else(|| Path::new("."));
    let temp_dir = tempfile::Builder::new()
        .prefix("rustresort-d1-sync-source-")
        .tempdir_in(parent)
        .map_err(|error| {
            AppError::Storage(format!(
                "failed to create D1 source snapshot temp directory: {error}"
            ))
        })?;
    let source_path = temp_dir.path().join(format!("source-{}.db", Ulid::new()));

    create_snapshot_from_db(db_path, &source_path).await?;

    Ok(SyncSourceSnapshot {
        _temp_dir: temp_dir,
        path: source_path,
    })
}

async fn d1_sync_key_exists(
    database: &str,
    config: &D1SyncConfig,
    sync_key: &str,
) -> Result<bool, AppError> {
    let table_check_sql = format!(
        "SELECT '{token}' WHERE EXISTS(SELECT 1 FROM sqlite_master WHERE type = 'table' AND name = '{table}');",
        token = D1_SYNC_HISTORY_TABLE_PRESENT_TOKEN,
        table = D1_SYNC_HISTORY_TABLE
    );
    let table_check_output =
        execute_wrangler_d1_command(database, config, &table_check_sql).await?;
    if !table_check_output.contains(D1_SYNC_HISTORY_TABLE_PRESENT_TOKEN) {
        return Ok(false);
    }

    let sync_key_escaped = escape_sql_literal(sync_key);
    let sync_key_check_sql = format!(
        "SELECT '{token}' WHERE EXISTS(SELECT 1 FROM \"{table}\" WHERE sync_key = '{sync_key}');",
        token = D1_SYNC_KEY_PRESENT_TOKEN,
        table = D1_SYNC_HISTORY_TABLE,
        sync_key = sync_key_escaped
    );
    let sync_key_check_output =
        execute_wrangler_d1_command(database, config, &sync_key_check_sql).await?;
    Ok(sync_key_check_output.contains(D1_SYNC_KEY_PRESENT_TOKEN))
}

async fn prune_sync_history(database: &str, config: &D1SyncConfig) -> Result<(), AppError> {
    if config.history_retention_count == 0 {
        return Ok(());
    }

    let retention = config.history_retention_count;
    let prune_sql = format!(
        r#"
DELETE FROM "{table}"
WHERE sync_key IN (
    SELECT sync_key
    FROM "{table}"
    ORDER BY sync_at DESC, sync_name DESC
    LIMIT -1 OFFSET {retention}
);
"#,
        table = D1_SYNC_HISTORY_TABLE,
        retention = retention
    );
    let _ = execute_wrangler_d1_command(database, config, &prune_sql).await?;
    Ok(())
}

async fn ensure_parent_dir(path: &Path) -> Result<(), AppError> {
    if let Some(parent) = path.parent() {
        tokio::fs::create_dir_all(parent)
            .await
            .map_err(|e| AppError::Storage(format!("failed to create directory: {e}")))?;
    }
    Ok(())
}

async fn path_exists(path: &Path) -> Result<bool, AppError> {
    match tokio::fs::metadata(path).await {
        Ok(_) => Ok(true),
        Err(error) if error.kind() == std::io::ErrorKind::NotFound => Ok(false),
        Err(error) => Err(AppError::Storage(format!(
            "failed to stat path {}: {error}",
            path.display()
        ))),
    }
}

async fn create_snapshot_from_db(db_path: &Path, snapshot_path: &Path) -> Result<(), AppError> {
    if path_exists(snapshot_path).await? {
        tokio::fs::remove_file(snapshot_path)
            .await
            .map_err(|e| AppError::Storage(format!("failed to remove old snapshot file: {e}")))?;
    }

    let vacuum_into = build_vacuum_into_sql(snapshot_path)?;
    let output = Command::new("sqlite3")
        .arg(db_path)
        .arg(vacuum_into)
        .output()
        .await
        .map_err(|e| AppError::Storage(format!("failed to create snapshot: {e}")))?;

    if !output.status.success() {
        let stderr = String::from_utf8_lossy(&output.stderr);
        return Err(AppError::Storage(format!(
            "failed to create snapshot: {}",
            stderr.trim()
        )));
    }

    Ok(())
}

async fn promote_snapshot(
    source_snapshot_path: &Path,
    target_snapshot_path: &Path,
) -> Result<(), AppError> {
    let parent = target_snapshot_path
        .parent()
        .unwrap_or_else(|| Path::new("."));
    let staged_target_path = parent.join(format!(
        ".rustresort-d1-snapshot-promote-{}.db",
        Ulid::new()
    ));

    tokio::fs::copy(source_snapshot_path, &staged_target_path)
        .await
        .map_err(|e| AppError::Storage(format!("failed to stage refreshed D1 snapshot: {e}")))?;

    if path_exists(target_snapshot_path).await? {
        tokio::fs::remove_file(target_snapshot_path)
            .await
            .map_err(|e| AppError::Storage(format!("failed to remove old D1 snapshot: {e}")))?;
    }

    if let Err(error) = tokio::fs::rename(&staged_target_path, target_snapshot_path).await {
        if path_exists(&staged_target_path).await.unwrap_or(false) {
            let _ = tokio::fs::remove_file(&staged_target_path).await;
        }
        return Err(AppError::Storage(format!(
            "failed to promote refreshed D1 snapshot: {error}"
        )));
    }

    Ok(())
}

async fn build_full_dump_sql(db_path: &Path) -> Result<Vec<u8>, AppError> {
    let reset_sql = build_reset_sql(db_path).await?;

    let dump_output = Command::new("sqlite3")
        .arg(db_path)
        .arg(".dump")
        .output()
        .await
        .map_err(|e| AppError::Storage(format!("failed to execute sqlite3: {e}")))?;

    if !dump_output.status.success() {
        let stderr = String::from_utf8_lossy(&dump_output.stderr);
        return Err(AppError::Storage(format!(
            "sqlite3 .dump failed: {}",
            stderr.trim()
        )));
    }

    let mut full_sql = reset_sql;
    full_sql.extend_from_slice(&dump_output.stdout);
    Ok(full_sql)
}

async fn build_diff_sql(snapshot_path: &Path, db_path: &Path) -> Result<Vec<u8>, AppError> {
    let diff_output = Command::new("sqldiff")
        .arg(snapshot_path)
        .arg(db_path)
        .output()
        .await
        .map_err(|e| {
            AppError::Storage(format!(
                "failed to execute sqldiff (install sqlite3 tools): {e}"
            ))
        })?;

    if !diff_output.status.success() {
        let stderr = String::from_utf8_lossy(&diff_output.stderr);
        return Err(AppError::Storage(format!(
            "sqldiff failed: {}",
            stderr.trim()
        )));
    }

    Ok(diff_output.stdout)
}

async fn build_reset_sql(db_path: &Path) -> Result<Vec<u8>, AppError> {
    let reset_query = r#"
SELECT CASE type
    WHEN 'view' THEN 'DROP VIEW IF EXISTS "' || REPLACE(name, '"', '""') || '";'
    WHEN 'table' THEN 'DROP TABLE IF EXISTS "' || REPLACE(name, '"', '""') || '";'
END
FROM sqlite_master
WHERE type IN ('view', 'table')
  AND name NOT LIKE 'sqlite_%'
ORDER BY CASE type WHEN 'view' THEN 0 ELSE 1 END, name;
"#;

    let reset_output = Command::new("sqlite3")
        .arg(db_path)
        .arg(reset_query)
        .output()
        .await
        .map_err(|e| AppError::Storage(format!("failed to build D1 reset SQL: {e}")))?;

    if !reset_output.status.success() {
        let stderr = String::from_utf8_lossy(&reset_output.stderr);
        return Err(AppError::Storage(format!(
            "failed to build D1 reset SQL: {}",
            stderr.trim()
        )));
    }

    let statements = String::from_utf8_lossy(&reset_output.stdout);
    let mut sql = String::from("PRAGMA foreign_keys=OFF;\n");
    if !statements.trim().is_empty() {
        sql.push_str(&statements);
        if !statements.ends_with('\n') {
            sql.push('\n');
        }
    }
    sql.push_str("PRAGMA foreign_keys=ON;\n");
    Ok(sql.into_bytes())
}

async fn execute_wrangler_d1(
    database: &str,
    config: &D1SyncConfig,
    sql_path: &Path,
) -> Result<(), AppError> {
    let mut wrangler = Command::new("wrangler");
    wrangler
        .arg("d1")
        .arg("execute")
        .arg(database)
        .arg("--file")
        .arg(sql_path);

    if config.remote {
        wrangler.arg("--remote");
    }

    if let Some(wrangler_config) = &config.wrangler_config {
        wrangler.arg("--config").arg(wrangler_config);
    }

    let output = wrangler
        .output()
        .await
        .map_err(|e| AppError::Storage(format!("failed to execute wrangler: {e}")))?;

    if !output.status.success() {
        let stderr = String::from_utf8_lossy(&output.stderr);
        return Err(AppError::Storage(format!(
            "wrangler d1 execute failed: {}",
            stderr.trim()
        )));
    }

    Ok(())
}

async fn execute_wrangler_d1_command(
    database: &str,
    config: &D1SyncConfig,
    sql: &str,
) -> Result<String, AppError> {
    let mut wrangler = Command::new("wrangler");
    wrangler
        .arg("d1")
        .arg("execute")
        .arg(database)
        .arg("--command")
        .arg(sql);

    if config.remote {
        wrangler.arg("--remote");
    }

    if let Some(wrangler_config) = &config.wrangler_config {
        wrangler.arg("--config").arg(wrangler_config);
    }

    let output = wrangler
        .output()
        .await
        .map_err(|e| AppError::Storage(format!("failed to execute wrangler: {e}")))?;

    if !output.status.success() {
        let stderr = String::from_utf8_lossy(&output.stderr);
        return Err(AppError::Storage(format!(
            "wrangler d1 execute failed: {}",
            stderr.trim()
        )));
    }

    Ok(String::from_utf8_lossy(&output.stdout).to_string())
}

fn validate_and_canonicalize_snapshot_path(
    db_path: &Path,
    snapshot_path: &Path,
) -> Result<PathBuf, AppError> {
    let canonical_db_path = canonicalize_for_compare(db_path)
        .map_err(|e| AppError::Storage(format!("failed to canonicalize database path: {e}")))?;
    let canonical_snapshot_path = canonicalize_for_compare(snapshot_path).map_err(|e| {
        AppError::Storage(format!(
            "failed to canonicalize D1 snapshot path {}: {e}",
            snapshot_path.display()
        ))
    })?;

    if canonical_db_path == canonical_snapshot_path {
        return Err(AppError::Config(format!(
            "database.sync.d1.snapshot_path must differ from database.path (both resolve to {})",
            canonical_db_path.display()
        )));
    }

    Ok(canonical_snapshot_path)
}

fn canonicalize_for_compare(path: &Path) -> std::io::Result<PathBuf> {
    if path.exists() {
        return std::fs::canonicalize(path);
    }

    let parent = match path.parent() {
        Some(parent) if !parent.as_os_str().is_empty() => parent,
        _ => Path::new("."),
    };
    let canonical_parent = std::fs::canonicalize(parent)?;
    let file_name = path.file_name().ok_or_else(|| {
        std::io::Error::new(
            std::io::ErrorKind::InvalidInput,
            format!("path does not contain file name: {}", path.display()),
        )
    })?;

    Ok(canonical_parent.join(file_name))
}

fn build_vacuum_into_sql(snapshot_path: &Path) -> Result<String, AppError> {
    let snapshot_path = snapshot_path.to_str().ok_or_else(|| {
        AppError::Config(format!(
            "database.sync.d1.snapshot_path must be valid UTF-8: {}",
            snapshot_path.display()
        ))
    })?;

    if snapshot_path.contains('\0') || snapshot_path.contains('\n') || snapshot_path.contains('\r')
    {
        return Err(AppError::Config(
            "database.sync.d1.snapshot_path must not contain control characters".to_string(),
        ));
    }

    Ok(format!(
        "VACUUM INTO '{}';",
        escape_sql_literal(snapshot_path)
    ))
}
